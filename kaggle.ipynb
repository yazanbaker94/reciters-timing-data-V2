{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Quran Word Aligner\nGenerate word-level timestamps for any Quran recitation using OpenAI Whisper.\n\n**Instructions:**\n1. Go to Runtime > Change runtime type > Select GPU (T4)\n2. Run all cells in order\n3. Upload your audio files or use EveryAyah URLs\n4. Download the output JSON","metadata":{}},{"cell_type":"code","source":"# Kaggle uses /kaggle/working/ for output\nimport os\nOUTPUT_DIR = \"/kaggle/working\"\nprint(f\"Output will be saved to {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:16:59.714039Z","iopub.execute_input":"2026-01-17T13:16:59.714848Z","iopub.status.idle":"2026-01-17T13:16:59.719346Z","shell.execute_reply.started":"2026-01-17T13:16:59.714815Z","shell.execute_reply":"2026-01-17T13:16:59.718737Z"}},"outputs":[{"name":"stdout","text":"Output will be saved to /kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Install dependencies\n!pip install -q openai-whisper python-Levenshtein tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:16:59.720934Z","iopub.execute_input":"2026-01-17T13:16:59.721329Z","iopub.status.idle":"2026-01-17T13:17:13.683070Z","shell.execute_reply.started":"2026-01-17T13:16:59.721298Z","shell.execute_reply":"2026-01-17T13:17:13.682120Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Check GPU\nimport torch\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:17:13.684888Z","iopub.execute_input":"2026-01-17T13:17:13.685196Z","iopub.status.idle":"2026-01-17T13:17:20.693739Z","shell.execute_reply.started":"2026-01-17T13:17:13.685166Z","shell.execute_reply":"2026-01-17T13:17:20.693004Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Download Quran text\nimport urllib.request\nprint(\"Downloading Quran text...\")\nurllib.request.urlretrieve(\n    \"https://tanzil.net/pub/download/index.php?quranType=uthmani&outType=txt-2&agree=true\",\n    \"quran-uthmani.txt\"\n)\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:17:20.695474Z","iopub.execute_input":"2026-01-17T13:17:20.695885Z","iopub.status.idle":"2026-01-17T13:17:21.857293Z","shell.execute_reply.started":"2026-01-17T13:17:20.695861Z","shell.execute_reply":"2026-01-17T13:17:21.856514Z"}},"outputs":[{"name":"stdout","text":"Downloading Quran text...\nDone!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Aligner code\nimport json\nimport os\nimport re\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple\nfrom tqdm import tqdm\nimport whisper\nimport Levenshtein\n\n@dataclass\nclass WordSegment:\n    word: str\n    start_ms: int\n    end_ms: int\n\n@dataclass\nclass AlignedSpan:\n    index_start: int\n    index_end: int\n    start_ms: int\n    end_ms: int\n\ndef normalize_arabic(text: str) -> str:\n    diacritics = re.compile(r'[\\u064B-\\u065F\\u0670]')\n    text = diacritics.sub('', text)\n    text = re.sub(r'[إأآا]', 'ا', text)\n    text = re.sub(r'ة', 'ه', text)\n    text = re.sub(r'ى', 'ي', text)\n    text = text.replace('\\u0640', '')\n    return text.strip()\n\ndef load_quran_text(quran_file: str) -> Dict[int, str]:\n    quran_text = {}\n    with open(quran_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line or line.startswith('#'):\n                continue\n            parts = line.split('|')\n            if len(parts) >= 3:\n                surah = int(parts[0])\n                ayah = int(parts[1])\n                text = parts[2]\n                key = surah * 1000 + ayah\n                quran_text[key] = text\n    return quran_text\n\ndef align_words(recognized: List[WordSegment], reference_words: List[str]) -> List[AlignedSpan]:\n    if not recognized or not reference_words:\n        return []\n    \n    rec_normalized = [normalize_arabic(w.word) for w in recognized]\n    ref_normalized = [normalize_arabic(w) for w in reference_words]\n    \n    n, m = len(rec_normalized), len(ref_normalized)\n    INF = float('inf')\n    dp = [[INF] * (m + 1) for _ in range(n + 1)]\n    dp[0][0] = 0\n    \n    for j in range(1, m + 1):\n        dp[0][j] = j * 0.8\n    for i in range(1, n + 1):\n        dp[i][0] = i * 1.2\n    \n    for i in range(1, n + 1):\n        for j in range(1, m + 1):\n            rec_word = rec_normalized[i-1]\n            ref_word = ref_normalized[j-1]\n            \n            if rec_word == ref_word:\n                cost = 0\n            else:\n                ratio = Levenshtein.ratio(rec_word, ref_word)\n                if ratio > 0.8:\n                    cost = 0.1\n                elif ratio > 0.6:\n                    cost = 0.4\n                elif ratio > 0.4:\n                    cost = 0.7\n                else:\n                    cost = 1.0\n            \n            dp[i][j] = min(\n                dp[i-1][j-1] + cost,\n                dp[i-1][j] + 1.2,\n                dp[i][j-1] + 0.8\n            )\n    \n    alignment = []\n    i, j = n, m\n    \n    while i > 0 or j > 0:\n        if i > 0 and j > 0:\n            rec_word = rec_normalized[i-1]\n            ref_word = ref_normalized[j-1]\n            \n            if rec_word == ref_word:\n                cost = 0\n            else:\n                ratio = Levenshtein.ratio(rec_word, ref_word)\n                if ratio > 0.8:\n                    cost = 0.1\n                elif ratio > 0.6:\n                    cost = 0.4\n                elif ratio > 0.4:\n                    cost = 0.7\n                else:\n                    cost = 1.0\n            \n            if abs(dp[i][j] - (dp[i-1][j-1] + cost)) < 0.001:\n                alignment.append((i-1, j-1))\n                i -= 1\n                j -= 1\n                continue\n        \n        if i > 0 and abs(dp[i][j] - (dp[i-1][j] + 1.2)) < 0.001:\n            alignment.append((i-1, None))\n            i -= 1\n        elif j > 0:\n            alignment.append((None, j-1))\n            j -= 1\n        else:\n            break\n    \n    alignment.reverse()\n    \n    spans = []\n    for rec_idx, aligned_ref_idx in alignment:\n        if rec_idx is not None and aligned_ref_idx is not None:\n            spans.append(AlignedSpan(\n                index_start=aligned_ref_idx,\n                index_end=aligned_ref_idx + 1,\n                start_ms=recognized[rec_idx].start_ms,\n                end_ms=recognized[rec_idx].end_ms\n            ))\n    \n    # Fill gaps\n    if spans and len(spans) < len(reference_words):\n        covered_indices = {s.index_start for s in spans}\n        span_by_idx = {s.index_start: s for s in spans}\n        filled_spans = []\n        \n        for ref_idx in range(len(reference_words)):\n            if ref_idx in covered_indices:\n                filled_spans.append(span_by_idx[ref_idx])\n            else:\n                next_span_idx = None\n                for idx in range(ref_idx + 1, len(reference_words)):\n                    if idx in covered_indices:\n                        next_span_idx = idx\n                        break\n                \n                prev_span = filled_spans[-1] if filled_spans else None\n                next_span = span_by_idx.get(next_span_idx) if next_span_idx else None\n                \n                if prev_span and next_span:\n                    gap_start = prev_span.end_ms\n                    gap_end = next_span.start_ms\n                    \n                    if gap_end > gap_start:\n                        gap_words = next_span_idx - ref_idx\n                        word_duration = (gap_end - gap_start) // gap_words\n                        filled_spans.append(AlignedSpan(\n                            index_start=ref_idx,\n                            index_end=ref_idx + 1,\n                            start_ms=gap_start,\n                            end_ms=gap_start + word_duration\n                        ))\n                    else:\n                        words_in_segment = list(range(ref_idx, next_span_idx + 1))\n                        next_duration = next_span.end_ms - next_span.start_ms\n                        word_lengths = [len(normalize_arabic(reference_words[i])) for i in words_in_segment]\n                        total_length = sum(word_lengths)\n                        \n                        current_start = next_span.start_ms\n                        for i, word_idx in enumerate(words_in_segment):\n                            proportion = word_lengths[i] / total_length if total_length > 0 else 1 / len(words_in_segment)\n                            word_duration = int(next_duration * proportion)\n                            \n                            if word_idx == ref_idx:\n                                filled_spans.append(AlignedSpan(\n                                    index_start=word_idx,\n                                    index_end=word_idx + 1,\n                                    start_ms=current_start,\n                                    end_ms=current_start + word_duration\n                                ))\n                            elif word_idx == next_span_idx:\n                                span_by_idx[next_span_idx] = AlignedSpan(\n                                    index_start=next_span_idx,\n                                    index_end=next_span_idx + 1,\n                                    start_ms=current_start,\n                                    end_ms=next_span.end_ms\n                                )\n                            current_start += word_duration\n                elif prev_span:\n                    avg_duration = max(prev_span.end_ms - prev_span.start_ms, 300)\n                    filled_spans.append(AlignedSpan(\n                        index_start=ref_idx,\n                        index_end=ref_idx + 1,\n                        start_ms=prev_span.end_ms,\n                        end_ms=prev_span.end_ms + avg_duration\n                    ))\n                elif next_span:\n                    avg_duration = max(next_span.end_ms - next_span.start_ms, 300)\n                    filled_spans.append(AlignedSpan(\n                        index_start=ref_idx,\n                        index_end=ref_idx + 1,\n                        start_ms=max(0, next_span.start_ms - avg_duration),\n                        end_ms=next_span.start_ms\n                    ))\n        \n        spans = filled_spans\n    \n    return spans\n\nprint(\"Aligner code loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:17:21.858206Z","iopub.execute_input":"2026-01-17T13:17:21.858456Z","iopub.status.idle":"2026-01-17T13:17:23.797310Z","shell.execute_reply.started":"2026-01-17T13:17:21.858433Z","shell.execute_reply":"2026-01-17T13:17:23.796693Z"}},"outputs":[{"name":"stdout","text":"Aligner code loaded!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Load Whisper model\nprint(\"Loading Whisper large-v3 model...\")\nmodel = whisper.load_model(\"large-v3\")\nprint(\"Model loaded!\")\n\n# Load Quran text\nquran_text = load_quran_text(\"quran-uthmani.txt\")\nprint(f\"Loaded {len(quran_text)} ayahs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:17:23.798353Z","iopub.execute_input":"2026-01-17T13:17:23.798691Z","iopub.status.idle":"2026-01-17T13:18:33.965517Z","shell.execute_reply.started":"2026-01-17T13:17:23.798667Z","shell.execute_reply":"2026-01-17T13:18:33.964825Z"}},"outputs":[{"name":"stdout","text":"Loading Whisper large-v3 model...\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████| 2.88G/2.88G [00:41<00:00, 73.6MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model loaded!\nLoaded 6236 ayahs\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Configuration - EDIT THIS\nRECITER = \"Muhammad_Jibreel_128kbps\"  # Reciter folder name on EveryAyah\nSURAH_START = 1   # Start surah (1-114)\nSURAH_END = 114   # End surah (1-114) - DO ALL BY DEFAULT\n\n# Save to Google Drive so progress is never lost!\nOUTPUT_FILE = \"/kaggle/working/alignment_output.json\"\n\n# Surah ayah counts\nAYAH_COUNTS = [\n    7, 286, 200, 176, 120, 165, 206, 75, 129, 109, 123, 111, 43, 52, 99, 128,\n    111, 110, 98, 135, 112, 78, 118, 64, 77, 227, 93, 88, 69, 60, 34, 30, 73,\n    54, 45, 83, 182, 88, 75, 85, 54, 53, 89, 59, 37, 35, 38, 29, 18, 45, 60,\n    49, 62, 55, 78, 96, 29, 22, 24, 13, 14, 11, 11, 18, 12, 12, 30, 52, 52,\n    44, 28, 28, 20, 56, 40, 31, 50, 40, 46, 42, 29, 19, 36, 25, 22, 17, 19,\n    26, 30, 20, 15, 21, 11, 8, 8, 19, 5, 8, 8, 11, 11, 8, 3, 9, 5, 4, 7, 3,\n    6, 3, 5, 4, 5, 6\n]\n\nprint(f\"Will process surahs {SURAH_START} to {SURAH_END}\")\nprint(f\"Output file: {OUTPUT_FILE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:18:33.966486Z","iopub.execute_input":"2026-01-17T13:18:33.966865Z","iopub.status.idle":"2026-01-17T13:18:33.973477Z","shell.execute_reply.started":"2026-01-17T13:18:33.966835Z","shell.execute_reply":"2026-01-17T13:18:33.972835Z"}},"outputs":[{"name":"stdout","text":"Will process surahs 1 to 114\nOutput file: /kaggle/working/alignment_output.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Download audio and process (with auto-save after EVERY AYAH)\nimport urllib.request\nimport os\n\nos.makedirs(\"audio\", exist_ok=True)\n\n# Load existing progress if any\nif os.path.exists(OUTPUT_FILE):\n    with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n        results = json.load(f)\n    processed = {(r['surah'], r['ayah']) for r in results}\n    last_surah = max(r['surah'] for r in results) if results else 0\n    print(f\"RESUMING - already have {len(results)} ayahs (up to surah {last_surah})\")\nelse:\n    results = []\n    processed = set()\n    print(\"Starting fresh\")\n\nsave_counter = 0\n\nfor surah in range(SURAH_START, SURAH_END + 1):\n    num_ayahs = AYAH_COUNTS[surah - 1]\n    \n    # Check if surah already complete\n    surah_ayahs_done = sum(1 for s, a in processed if s == surah)\n    if surah_ayahs_done == num_ayahs:\n        print(f\"Surah {surah} already complete, skipping\")\n        continue\n    \n    print(f\"\\nProcessing Surah {surah} ({num_ayahs} ayahs)...\")\n    \n    for ayah in tqdm(range(1, num_ayahs + 1), desc=f\"Surah {surah}\"):\n        # Skip if already processed\n        if (surah, ayah) in processed:\n            continue\n            \n        filename = f\"{surah:03d}{ayah:03d}.mp3\"\n        url = f\"https://everyayah.com/data/{RECITER}/{filename}\"\n        local_path = f\"audio/{filename}\"\n        \n        # Download if not exists\n        if not os.path.exists(local_path):\n            try:\n                urllib.request.urlretrieve(url, local_path)\n            except Exception as e:\n                print(f\"Failed to download {filename}: {e}\")\n                continue\n        \n        # Get reference text\n        key = surah * 1000 + ayah\n        if key not in quran_text:\n            print(f\"No reference text for {surah}:{ayah}\")\n            continue\n        \n        reference = quran_text[key]\n        reference_words = reference.split()\n        \n        # Transcribe\n        try:\n            result = model.transcribe(local_path, language=\"ar\", word_timestamps=True)\n            \n            words = []\n            for segment in result.get(\"segments\", []):\n                for word_info in segment.get(\"words\", []):\n                    word = word_info.get(\"word\", \"\").strip()\n                    if word:\n                        words.append(WordSegment(\n                            word=word,\n                            start_ms=int(word_info[\"start\"] * 1000),\n                            end_ms=int(word_info[\"end\"] * 1000)\n                        ))\n            \n            spans = align_words(words, reference_words)\n            \n            results.append({\n                \"surah\": surah,\n                \"ayah\": ayah,\n                \"segments\": [[s.index_start, s.index_end, s.start_ms, s.end_ms] for s in spans]\n            })\n            processed.add((surah, ayah))\n            save_counter += 1\n            \n            # Auto-save every 10 ayahs\n            if save_counter >= 10:\n                with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n                    json.dump(results, f, ensure_ascii=False)\n                save_counter = 0\n                \n        except Exception as e:\n            print(f\"Error processing {surah}:{ayah}: {e}\")\n    \n    # Also save after each surah completes\n    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n        json.dump(results, f, ensure_ascii=False)\n    print(f\"Surah {surah} done! Total: {len(results)} ayahs saved\")\n\nprint(f\"\\n=== COMPLETE! Processed {len(results)} ayahs ===\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:18:33.974489Z","iopub.execute_input":"2026-01-17T13:18:33.974683Z","iopub.status.idle":"2026-01-17T13:19:00.119519Z","shell.execute_reply.started":"2026-01-17T13:18:33.974665Z","shell.execute_reply":"2026-01-17T13:19:00.118494Z"}},"outputs":[{"name":"stdout","text":"Starting fresh\n\nProcessing Surah 1 (7 ayahs)...\n","output_type":"stream"},{"name":"stderr","text":"Surah 1: 100%|██████████| 7/7 [00:24<00:00,  3.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Surah 1 done! Total: 7 ayahs saved\n\nProcessing Surah 2 (286 ayahs)...\n","output_type":"stream"},{"name":"stderr","text":"Surah 2:   0%|          | 0/286 [00:01<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/712252900.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Transcribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_timestamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword_timestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 add_word_timestamps(\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0msegments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_segments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/timing.py\u001b[0m in \u001b[0;36madd_word_timestamps\u001b[0;34m(segments, model, tokenizer, mel, num_frames, prepend_punctuations, append_punctuations, last_speech_timestamp, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mtext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tokens_per_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0mword_durations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malignment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mword_durations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_durations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/timing.py\u001b[0m in \u001b[0;36mfind_alignment\u001b[0;34m(model, tokenizer, text_tokens, mel, num_frames, medfilt_width, qk_scale)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_sdpa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0msampled_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msot_sequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mtoken_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mel, tokens)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     ) -> Dict[str, torch.Tensor]:\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     ):\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"## Available Reciters on EveryAyah\n\nChange `RECITER` to any of these:\n- `Abdullah_Basfar_64kbps`\n- `Husary_64kbps`\n- `Minshawy_Murattal_128kbps`\n- `Abdul_Basit_Murattal_64kbps`\n- `Alafasy_64kbps`\n- `Sudais_64kbps`\n- And many more at https://everyayah.com/data/","metadata":{}}]}